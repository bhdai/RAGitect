# Database Configuration
# Use postgresql+asyncpg:// for async SQLAlchemy runtime
# Alembic will automatically convert to postgresql+psycopg2:// for migrations
DATABASE_URL=postgresql+asyncpg://admin:admin@localhost:5432/ragitect_db

# Encryption Configuration
# Generate key with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
ENCRYPTION_KEY=your-encryption-key-here

# LLM Configuration
LLM_PROVIDER="your-llm-provider"
LLM_MODEL="your-llm-model"
LLM_API_KEY="your-llm-api-key"
LLM_TEMPERATURE=0.7

# Document Processing Configuration
# CHUNK_SIZE: Target chunk size in characters (default: 1000)
# CHUNK_OVERLAP: Overlap between chunks in characters (default: 150)
# These values are optimized for modern embedding models (512-1024 token inputs)
# CHUNK_SIZE=1000
# CHUNK_OVERLAP=150

# Multi-Stage Retrieval Pipeline Configuration (Story 3.1.2)
# RETRIEVAL_INITIAL_K: Number of candidates to over-retrieve (default: 50)
# RETRIEVAL_RERANKER_TOP_K: Number of top reranked chunks to pass to MMR (default: 30)
# RETRIEVAL_MMR_K: Number of diverse chunks to select via MMR (default: 20)
# RETRIEVAL_USE_RERANKER: Enable cross-encoder reranking (default: True)
# RETRIEVAL_USE_MMR: Enable MMR diversity selection (default: True)
# RETRIEVAL_USE_ADAPTIVE_K: Enable adaptive K selection based on score gaps (default: True)
# RETRIEVAL_MMR_LAMBDA: Balance between relevance (1.0) and diversity (0.0) (default: 0.7)
# RETRIEVAL_ADAPTIVE_K_MIN: Minimum chunks to return (default: 4)
# RETRIEVAL_ADAPTIVE_K_MAX: Maximum chunks to return (default: 16)
# RETRIEVAL_TOKEN_BUDGET: Max tokens for context (default: 4000, optional)
# RETRIEVAL_INITIAL_K=50
# RETRIEVAL_RERANKER_TOP_K=30
# RETRIEVAL_MMR_K=20
# RETRIEVAL_USE_RERANKER=True
# RETRIEVAL_USE_MMR=True
# RETRIEVAL_USE_ADAPTIVE_K=True
# RETRIEVAL_MMR_LAMBDA=0.7
# RETRIEVAL_ADAPTIVE_K_MIN=4
# RETRIEVAL_ADAPTIVE_K_MAX=16
# RETRIEVAL_TOKEN_BUDGET=4000
